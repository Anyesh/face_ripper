'''
Now that your videos have had each frame turned into a jpg in step one,
AND we have taken those video frame jpgs and taken an equal, random sample of 500 images from each,
and placed all of those into one folder...
We will now run this facial recognition script to look at how many faces are in each image.

This script is not looking to recognize the face you are trying to rip for your dataset.
This script is only looking to delete every photo that has ZERO faces or MORE THAN ONE face.
This will prevent our final faceset from showing the model more than one face in a photo, or wasting
compute time on a photo with no faces.

This will of course delete some photos your target face is in when there is another face in the photo next to it,
AND it will select photos with a single face that is NOT your target face,
BUT the next step (step four) will delete the faces you don't want in the next step,
AND your input videos hopefully had enough footage of your target face alone in the frame in order to have a healthy range
of light, emotions, and angles.
AGAIN:
This step illustrates why the ideal videos for your face are not video files of the face staring in an entire movie,
but rather a shorter clip with the target face giving a lot of 1080p face time in a range of emotions.
For example: It's much faster to rip climactic three minute scenes of Kristen Stewart from Twilight, AND 1080p Kristen
Stewart five minute interviews than to feed the entire movie Twighlight through this process.


The files input into this script were generated by the previous script, 2_copy.py
'''

import glob
import uuid
import os, random
from PIL import Image
import face_recognition

try:
	if not os.makedirs('/home/eagle/Aly/_0_0_0_kaylee/faced'):
		os.makedirs('/home/eagle/Aly/_0_0_0_kaylee/faced')
except OSError:
	print ('Error: Creating directory of data')

trash = ('/home/eagle/Aly/_0_0_0_kaylee/trash_face')
try:
	if not os.path.exists(trash):
		os.makedirs(trash)
except OSError:
	print ('Error: Creating directory of data')

problem_file = ('/home/eagle/Aly/_0_0_0_kaylee/problem_file')
try:
	if not os.path.exists(problem_file):
		os.makedirs(problem_file)
except OSError:
	print ('Error: Creating directory of data')

for i in range (3):

	# Load the jpg file into a numpy array
	aly = (random.choice(glob.glob('/home/eagle/Aly/_0_0_0_kaylee/samped/'+'*.jpg')))
	image = face_recognition.load_image_file(aly)

	print (str(aly))

	# Find all the faces in the image using a pre-trained convolutional neural network.
	# This method is more accurate than the default HOG model, but it's slower
	# unless you have an nvidia GPU and dlib compiled with CUDA extensions. But if you do,
	# this will use GPU acceleration and perform well.
	# See also: find_faces_in_picture.py
	face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model="cnn")

	print("I found {} face(s) in this photograph.".format(len(face_locations)))

	if not (len(face_locations)) == 1:
		os.rename(aly, trash + '/' + str(uuid.uuid4()) + '.jpg')
	try:
		os.rename(aly, '/home/eagle/Aly/_0_0_0_kaylee/faced/' + str(uuid.uuid4()) + '.jpg')
	except:
		pass
#	except:
#		os.rename(aly, problem_file + '/' + str(uuid.uuid4()) + '.jpg')
#		pass


# We will now process the images created by this script in the next script, 4_the_face.py 

# Make a back up of the images this script created before going on to the next step.
# Compress it into a .zip file to ensure it is untouched in case you need to redo the next step.
